---
icon: lucide/rocket
---

# LLM Supervised Fine-Tuning Workshop

<figure markdown="span">
![logo](./images/logo_light.svg#only-light)
![logo](./images/logo_dark.svg#only-dark)
</figure>

Welcome, and thank you for your interest in this hands-on workshop organized by **[HES-SO Valais-Wallis](https://www.hes-so.ch/en/homepage)** and **[HEIG-VD](https://heig-vd.ch)** as part of a **[Swiss AI Center](https://www.hes-so.ch/en/swiss-ai-center)** cheque supported by **[Exoscale](https://www.exoscale.com)**!

This workshop aims at demystifying the process of [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)) [large language models (LLMs)](https://en.wikipedia.org/wiki/Large_language_model) by guiding you through the entire workflow, using open-source tools and modern cloud infrastructure.

**Here is what you will learn:**

By the end, you will be able to:

-  prepare datasets for training,
-  train models efficiently from a single GPU to multi-GPU setups,
-  track training progress in real time,
-  evaluate performance of fine-tuned models,
-  deploy your model, and even interact with it.

**Points of contact and contributors:**

- Andrei Coman ([andrei.coman@hevs.ch](mailto:andrei.coman@hevs.ch))
- Pamela Delgado ([pamela.delgado@heig-vd.ch](mailto:pamela.delgado@heig-vd.ch))
- Olivier Lemer
- RÃ©my Marquis