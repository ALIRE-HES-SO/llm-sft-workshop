#+-------------+------------------------------------------------------------------------------------
#| ExtraConfig |
#+-------------+

mode: train
model_class: AutoModelForCausalLM
dataset_name: gretelai/synthetic_text_to_sql
prompts_path: ./prompts/gretelai/synthetic_text_to_sql
dataset_test_split: test
dataset_train_split: train
fine_tuning_data_format: conversational_prompt_completion

#+-------------+------------------------------------------------------------------------------------
#| ModelConfig |
#+-------------+

dtype: bfloat16
trust_remote_code: true
model_name_or_path: google/gemma-3-270m-it
attn_implementation: eager

#+-----------+--------------------------------------------------------------------------------------
#| SFTConfig |
#+-----------+

run_name: google/gemma-3-270m-it-gretelai/synthetic_text_to_sql
dataset_num_proc: 8

seed: 42
bf16: true
ddp_find_unused_parameters: true
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false

warmup_ratio: 0.1
logging_steps: 1
learning_rate: 2e-5
lr_scheduler_type: cosine
per_device_train_batch_size: 4

report_to: wandb
num_train_epochs: 1

output_dir: ./trainer_output/google/gemma-3-270m-it-gretelai/synthetic_text_to_sql
resume_from_checkpoint: false

save_strategy: epoch